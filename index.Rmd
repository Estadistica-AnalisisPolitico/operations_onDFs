<center><img src="https://github.com/Estadistica-AnalisisPolitico/operations_onDFs/blob/main/Logo2025.png?raw=true" width="700"/></center>

Profesor:[Dr. José Manuel MAGALLANES REYES, Ph.D](http://www.pucp.edu.pe/profesor/jose-manuel-magallanes/" target="_blank) <br>

-   Profesor Principal del Departamento de Ciencias Sociales, Sección de Ciencia Política y Gobierno.

-   [Oficina 223](https://goo.gl/maps/xuGeG6o9di1i1y5m6) - Edificio CISEPA / ECONOMIA / CCSS
-   Telefono: (51) 1 - 6262000 anexo 4302
-   Correo Electrónico: [jmagallanes\@pucp.edu.pe](mailto:jmagallanes@pucp.edu.pe)


Operations on Data Frames

# Aggregation

Let's bring some data of COVID from Brazil:

```{r}
rm(list = ls())
linkCovid='https://github.com/Estadistica-AnalisisPolitico/operations_onDFs/raw/refs/heads/main/data/BrasilCovid.rds'
dataCovid=readRDS(url(linkCovid))
```



Now, check the data available:

```{r}
str(dataCovid)
```

Let's keep complete data by "ESTADO":

```{r}
dataCovid=dataCovid[dataCovid$estado!="",]
```

Let's keep some columns:

```{r}

toSelect=c('regiao', 'estado', 'municipio','data', 'semanaEpi','casosNovos', 'obitosNovos','day','year','month')
covid=dataCovid[,toSelect]

head(covid)
```


Let's find out about years available:

```{r}
unique(covid$year)
```

```{r}
unique(covid$month)
```

So, we have data from January to July 2022. Let's find out: **count of new positive cases per month**:

```{r}

for (month in unique(covid$month)) {
    print(paste(month,sum(covid$casosNovos[covid$month==month])))}
```

We use **aggregation** to simplify the previous steps:

```{r}
# sum of cases by month
casesSumByMonth=aggregate(data=covid,casosNovos~month,sum)
casesSumByMonth
```

Notice the structure:
```{r}
is.data.frame(casesSumByMonth)
```


**AGGREGATING** capabilities allow us to produce useful output with few code:

-   **The groupings**:

In the last example, *month* was the **grouping** variable. We can have more than one:

```{r}
# sum of cases by estado and month
theModel=casosNovos~estado + month
theFun=sum
casesSumByStateAndMonth=aggregate(data=covid,
                                  theModel,
                                  theFun)
casesSumByStateAndMonth
```

-   **The function to apply**:

We can have more than one function:

```{r}
# sum and mean of cases by estado and week
theModel=casosNovos~estado + semanaEpi
theFun=function(x) c(mean = mean(x), sum = sum(x) ) 
casesSumAndMeanByStateAndWeek=aggregate(data=covid,
                                        theModel,
                                        theFun)

# can you see?
head(casesSumAndMeanByStateAndWeek,30)
```
```{r}
is.data.frame(casesSumAndMeanByStateAndWeek)
```

So, turn the aggregation explicitly into a dataframe:

```{r}
casesSumAndMeanByStateAndWeek=do.call(data.frame,
                                      aggregate(data=covid,
                                                theModel,
                                                theFun))
head(casesSumAndMeanByStateAndWeek,30)
```

-   **The variables transformed**:

We can apply the function to more than one variable:

```{r}
# sum of cases and deaths by estado
theModel=cbind(casosNovos,obitosNovos)~estado
theFun=sum
CasesAndDeathsByState=aggregate(data=covid,
                                theModel,
                                theFun)

head(CasesAndDeathsByState,30)
```

-   Function **according** to variable

The function can vary according to variable. In this case, using **dplyr** is needed:

```{r, warning=FALSE}
library(dplyr)
covid |>
  group_by(month) |>
  summarize(casosNovos_VAR = var(casosNovos),
            casosNovos_SD = sd(casosNovos),
            obitosNovos_Median = median(obitosNovos),
            obitosNovos_Mean = mean(obitosNovos))
```


# Concatenation

As the name implies, it is the process to unite dataframes. 

For this example, there is a webpage in **fragilestatesindex.org** where we can find several links to excel files. Let me get all the links:

```{r, eval=FALSE}
library(rvest) 
  
# Read the HTML content of the website 
webpage <- read_html("https://fragilestatesindex.org/excel/") 
  
 
allLinks=html_nodes(webpage,"table") %>%
            html_nodes("a") %>% #“a” nodes contain linked text.
                html_attr("href")%>% # the url (an html attribute)
                    trimws()%>%unique() # cleaning and keeping non duplicated
allLinks
```

Now, I will create a list of data frames by loading the data from those links:


```{r, eval=FALSE}
dfs = lapply(allLinks, rio::import,col_types = "text")
```

Can we concatenate the files now?

```{r, eval=FALSE}
do.call(rbind, dfs)
```
It is not possible due to the column names differences in each dataframe (DF).

We can solve this. Let's build a list where each element is the column names of each DF:


```{r, eval=FALSE}
allNames=list()
i=1 
for (df in dfs){
    allNames[[i]]=names(df)
    i=i+1
}
```

Let me find WHAT is common in all DFs:


```{r, eval=FALSE}
Reduce(intersect, allNames)

```

If this is the union of all the column names:
```{r, eval=FALSE}
Reduce(union, allNames)
```

This is what is NOT common:
```{r, eval=FALSE}
setdiff(Reduce(union, allNames),Reduce(intersect, allNames))
```

I will force that each DF has the same names and in the same position:
```{r, eval=FALSE}
allInCommon=Reduce(intersect, allNames)

for (i in 1:length(dfs)){
    dfs[[i]]=dfs[[i]][,allInCommon] #forcing!
}
```

Now we can concatenate all of them:

```{r, eval=FALSE}
allFragility=do.call(rbind, dfs)
```

Let's check:
```{r, eval=FALSE}
str(allFragility)
```

The names can be cleaned and reorganized (sort):

```{r, eval=FALSE}
# what names?
grep(':',names(allFragility),value = T)
```

```{r, eval=FALSE}
# no spaces and to lowercase
gsub(":\\s|\\s","_",grep(':',names(allFragility),value = T))%>%tolower()
```

```{r, eval=FALSE}
# sorted new names
newNames=sort(gsub(":\\s|\\s","_",grep(':',names(allFragility),value = T))%>%tolower())

# then
names(allFragility)=c(names(allFragility)[1:4],newNames)
str(allFragility)
```
Let's check some possible errors knowing the origin was an excel file:

- The year:
```{r, eval=FALSE}
table(allFragility$Year)
```

The numeric format tells us the representation of a date:

```{r, eval=FALSE}
as.Date(38718, origin="1899-12-30")
```

This looks like an easy fix, just verify we have integers:

```{r, eval=FALSE}
str(allFragility$Year)
```

Then,
```{r, eval=FALSE}
allFragility$Year=as.numeric(allFragility$Year)
```

We have two years well written, then:

```{r, eval=FALSE}
# temproral Column:
allFragility$Year2=format(as.Date(allFragility$Year,
                                  origin="1899-12-30"),
                          "%Y") # I will just recover the year.

# improved column
allFragility$Year=ifelse(allFragility$Year%in%c(2021,2023),
                         allFragility$Year,
                         allFragility$Year2)

# deleting temporal
allFragility$Year2=NULL

# as numeric
allFragility$Year=as.numeric(allFragility$Year)
# now
table(allFragility$Year)
```
Recheck data types:

```{r}
str(allFragility)
```

- The numeric columns as numeric:

```{r, eval=FALSE}
allFragility[,-c(1:3)]=lapply(allFragility[,-c(1:3)],as.numeric)
```

Verifying:

```{r, eval=FALSE}
str(allFragility)
```


We have concatenated, cleaned and formatted successfully

```{r, eval=FALSE}
saveRDS(allFragility,'allFragility.rds')
```



