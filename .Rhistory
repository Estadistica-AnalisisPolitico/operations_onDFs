casesSumByMonth=aggregate(data=covid,casosNovos~month,sum)
casesSumByMonth
typeof(casesSumByMonth)
str(casesSumByMonth)
is.data.frame(casesSumByMonth)
# sum of cases by estado and week
casesSumByStateAndMonth=aggregate(data=covid,casosNovos~estado + month,sum)
casesSumByStateAndMonth
# sum and mean of cases by estado and week
casesSumAndMeanByStateAndWeek=aggregate(data=covid,casosNovos~estado + semanaEpi,
function(x) c(mean = mean(x), sum = sum(x) ) )
head(casesSumAndMeanByStateAndWeek,30)
casesSumAndMeanByStateAndWeek=do.call(data.frame, aggregate(data=covid,casosNovos~estado + semanaEpi,
function(x) c(mean = mean(x), sum = sum(x) ) ))
head(casesSumAndMeanByStateAndWeek,30)
is.data.frame(casesSumAndMeanByStateAndWeek)
str(casesSumAndMeanByStateAndWeek)
# sum and mean of cases by estado and week
casesSumAndMeanByStateAndWeek=aggregate(data=covid,casosNovos~estado + semanaEpi,
function(x) c(mean = mean(x), sum = sum(x) ) )
head(casesSumAndMeanByStateAndWeek,30)
str(casesSumAndMeanByStateAndWeek)
is.data.frame(casesSumAndMeanByStateAndWeek)
# sum of cases by estado and month
model=formula(casosNovos~estado + month)
casesSumByStateAndMonth=aggregate(data=covid,
model,
sum)
casesSumByStateAndMonth
# sum of cases by estado and month
model=formula(casosNovos~estado + month)
theFun=sum
casesSumByStateAndMonth=aggregate(data=covid,
model,
theFun)
casesSumByStateAndMonth
# sum and mean of cases by estado and week
model=casosNovos~estado + semanaEpi
theFun=function(x) c(mean = mean(x), sum = sum(x) )
casesSumAndMeanByStateAndWeek=aggregate(data=covid,
model,
theFun)
head(casesSumAndMeanByStateAndWeek,30)
casesSumAndMeanByStateAndWeek
is.data.frame(casesSumAndMeanByStateAndWeek)
casesSumAndMeanByStateAndWeek=do.call(data.frame,
aggregate(data=covid,
model,
theFun()))
casesSumAndMeanByStateAndWeek=do.call(data.frame,
aggregate(data=covid,
model,
theFun)
head(casesSumAndMeanByStateAndWeek,30)
casesSumAndMeanByStateAndWeek=do.call(data.frame,
aggregate(data=covid,
model,
theFun))
head(casesSumAndMeanByStateAndWeek,30)
# sum of cases and deaths by estado
theModel=cbind(casosNovos,obitosNovos)~estado
CasesAndDeathsByState=aggregate(data=covid,
theModel,
sum)
head(CasesAndDeathsByState,30)
# sum of cases by estado and month
theModel=casosNovos~estado + month
theFun=sum
casesSumByStateAndMonth=aggregate(data=covid,
theModel,
theFun)
casesSumByStateAndMonth
# sum and mean of cases by estado and week
theModel=casosNovos~estado + semanaEpi
theFun=function(x) c(mean = mean(x), sum = sum(x) )
casesSumAndMeanByStateAndWeek=aggregate(data=covid,
theModel,
theFun)
# can you see?
head(casesSumAndMeanByStateAndWeek,30)
casesSumAndMeanByStateAndWeek=do.call(data.frame,
aggregate(data=covid,
theModel,
theFun))
head(casesSumAndMeanByStateAndWeek,30)
# sum of cases and deaths by estado
theModel=cbind(casosNovos,obitosNovos)~estado
theFun=sum
CasesAndDeathsByState=aggregate(data=covid,
theModel,
theFun)
head(CasesAndDeathsByState,30)
library(dplyr)
covid |>
group_by(month) |>
summarize(casosNovos_VAR = var(casosNovos),
casosNovos_SD = sd(casosNovos),
obitosNovos_Median = median(obitosNovos),
obitosNovos_Mean = mean(obitosNovos))
library(dplyr)
covid |>
group_by(month) |>
summarize(casosNovos_VAR = var(casosNovos),
casosNovos_SD = sd(casosNovos),
obitosNovos_Median = median(obitosNovos),
obitosNovos_Mean = mean(obitosNovos))
library(rvest)
# Read the HTML content of the website
webpage <- read_html("https://fragilestatesindex.org/excel/")
allLinks=html_nodes(webpage,"table") %>%
html_nodes("a") %>% #“a” nodes contain linked text.
html_attr("href")%>% # the url (an html attribute)
trimws()%>%unique() # cleaning and keeping non duplicated
allLinks
dfs = lapply(allLinks, rio::import,col_types = "text")
do.call(rbind, dfs)
allNames=list()
i=1
for (df in dfs){
allNames[[i]]=names(df)
i=i+1
}
Reduce(intersect, allNames)
Reduce(union, allNames)
setdiff(Reduce(union, allNames),Reduce(intersect, allNames))
allInCommon=Reduce(intersect, allNames)
for (i in 1:length(dfs)){
dfs[[i]]=dfs[[i]][,allInCommon] #forcing!
}
allFragility=do.call(rbind, dfs)
str(allFragility)
# what names?
grep(':',names(allFragility),value = T)
# no spaces and to lowercase
gsub(":\\s|\\s","_",grep(':',names(allFragility),value = T))%>%tolower()
# sorted new names
newNames=sort(gsub(":\\s|\\s","_",grep(':',names(allFragility),value = T))%>%tolower())
# then
names(allFragility)=c(names(allFragility)[1:4],newNames)
str(allFragility)
table(allFragility$Year)
str(allFragility$Year)
allFragility$Year=as.numeric(allFragility$Year)
# temproral Column:
allFragility$Year2=format(as.Date(allFragility$Year,
origin="1899-12-30"),
"%Y") # I will just recover the year.
# improved column
allFragility$Year=ifelse(allFragility$Year%in%c(2021,2023),
allFragility$Year,
allFragility$Year2)
# deleting temporal
allFragility$Year2=NULL
allFragility[,4:16]=lapply(allFragility[4:16],as.numeric)
str(allFragility)
table(allFragility$Year)
# temproral Column:
allFragility$Year2=format(as.Date(allFragility$Year,
origin="1899-12-30"),
"%Y") # I will just recover the year.
library(rvest)
# Read the HTML content of the website
webpage <- read_html("https://fragilestatesindex.org/excel/")
allLinks=html_nodes(webpage,"table") %>%
html_nodes("a") %>% #“a” nodes contain linked text.
html_attr("href")%>% # the url (an html attribute)
trimws()%>%unique() # cleaning and keeping non duplicated
allLinks
dfs = lapply(allLinks, rio::import,col_types = "text")
do.call(rbind, dfs)
allNames=list()
i=1
for (df in dfs){
allNames[[i]]=names(df)
i=i+1
}
Reduce(intersect, allNames)
Reduce(union, allNames)
setdiff(Reduce(union, allNames),Reduce(intersect, allNames))
allInCommon=Reduce(intersect, allNames)
for (i in 1:length(dfs)){
dfs[[i]]=dfs[[i]][,allInCommon] #forcing!
}
allFragility=do.call(rbind, dfs)
str(allFragility)
# what names?
grep(':',names(allFragility),value = T)
# no spaces and to lowercase
gsub(":\\s|\\s","_",grep(':',names(allFragility),value = T))%>%tolower()
# sorted new names
newNames=sort(gsub(":\\s|\\s","_",grep(':',names(allFragility),value = T))%>%tolower())
# then
names(allFragility)=c(names(allFragility)[1:4],newNames)
str(allFragility)
table(allFragility$Year)
as.Date(38718, origin="1899-12-30")
str(allFragility$Year)
allFragility$Year=as.numeric(allFragility$Year)
# temproral Column:
allFragility$Year2=format(as.Date(allFragility$Year,
origin="1899-12-30"),
"%Y") # I will just recover the year.
# improved column
allFragility$Year=ifelse(allFragility$Year%in%c(2021,2023),
allFragility$Year,
allFragility$Year2)
# deleting temporal
allFragility$Year2=NULL
# as numeric
allFragility$Year=as.numeric(allFragility$Year)
# now
table(allFragility$Year)
str(allFragility)
allFragility[,-c(1:3)]
allFragility[,-c(1:3)]=lapply(allFragility[,-c(1:3)],as.numeric)
str(allFragility)
saveRDS(allFragility,'allFragility.rds')
linkFragile='https://github.com/Estadistica-AnalisisPolitico/operations_onDFs/raw/refs/heads/main/data/allFragility.rds'
fragile=readRDS(url(linkFragile))
str(fragile)
table(fragile$Year)
head(fragile)
head(fragile[,c('Country','Year','Total')])
head(fragile[fragile$Year==2023,c('Country','C1_Security_Apparatus',	'C2_Factionalized_Elites',	'C3_Group_Grievance')])
head(fragile[fragile$Year==2023,c('Country','c1_security_apparatus',	'c2_factionalized_elites',	'c3_group_grievance')])
fragileWide=tidyr::pivot_wider(fragile[,c('Country','Year','Total')],names_from = Year, values_from = Total,names_sort=T)
fragileWide
boxplot(fragileWide[,-1])
library(ggplot2)
base=ggplot(fragileWide)
base+geom_boxplot(aes(x=as.ordered(2006),y=`2006`)) +
geom_boxplot(aes(x=as.ordered(2010),y=`2010`)) +
geom_boxplot(aes(x=as.ordered(2015),y=`2015`)) + labs(y='')
fragileLong=tidyr::pivot_longer(fragileWide,!Country, names_to = "Year", values_to = "FragilityIndex")
fragileLong
base = ggplot(data=fragileLong)
base + geom_boxplot(aes(x=Year,y=FragilityIndex))
boxplot(data=fragileLong,FragilityIndex~Year)
CVars_columns=c('c1_security_apparatus',	'c2_factionalized_elites',	'c3_group_grievance')
#only one year
fragile_CVars_wide=fragile[fragile$Year==2020,c('Country',CVars_columns)]
fragile_CVars_wide
boxplot(fragile_CVars_wide[,-1])
fragile_CVars_long=tidyr::pivot_longer(fragile_CVars_wide,!Country, names_to = "CVars_name", values_to = "CVars_value")
fragile_CVars_long
base=ggplot(data=fragile_CVars_long)
base+geom_boxplot(aes(x=CVars_name,y=CVars_value))
fragile_since2020=fragile[fragile$Year>=2020,c('Country','Year',CVars_columns)]
fragile_since2020
fragile_since2020_wide=tidyr::pivot_wider(fragile_since2020,names_from = Year, values_from = CVars_columns)
fragile_since2020_wide
fragile_since2020_wide=tidyr::pivot_wider(fragile_since2020,names_from = Year, values_from = all_of(CVars_columns))
fragile_since2020_wide
#save your work!
write.csv(fragile_since2020_wide,'fragile_since2020_wide.csv', row.names=F )
fragile_since2020_long=tidyr::pivot_longer(fragile_since2020,!c(Country,Year),names_to = "CVars_name", values_to = "CVars_value")
fragile_since2020_long
getcwd()
getwd()
# woking on the names that have a ':'
grep(':',names(allFragility),value = T)
library(rvest)
# Read the HTML content of the website
webpage <- read_html("https://fragilestatesindex.org/excel/")
allLinks=html_nodes(webpage,"table") %>%
html_nodes("a") %>% #“a” nodes contain linked text.
html_attr("href")%>% # the url (an html attribute)
trimws()%>%unique() # cleaning and keeping non duplicated
allLinks
allNames=list()
i=1
for (df in dfs){
allNames[[i]]=names(df)
i=i+1
}
Reduce(intersect, allNames)
Reduce(union, allNames)
setdiff(Reduce(union, allNames),Reduce(intersect, allNames))
dfs = lapply(allLinks, rio::import,col_types = "text")
allNames=list()
i=1
for (df in dfs){
allNames[[i]]=names(df)
i=i+1
}
Reduce(intersect, allNames)
Reduce(union, allNames)
setdiff(Reduce(union, allNames),Reduce(intersect, allNames))
allInCommon=Reduce(intersect, allNames)
for (i in 1:length(dfs)){
dfs[[i]]=dfs[[i]][,allInCommon] #forcing!
}
allFragility=do.call(rbind, dfs)
str(allFragility)
# woking on the names that have a ':'
grep(':',names(allFragility),value = T)
# no spaces and to lowercase
gsub(":\\s|\\s","_",grep(':',names(allFragility),value = T))%>%tolower()
columnNamesToClean=grep(':',names(allFragility),value = T)
# no spaces and to lowercase
gsub(":\\s|\\s","_",columnNamesToClean%>%tolower()
# woking on the names that have a ':'
grep(':',names(allFragility),value = T)
columnNamesToClean=grep(':',names(allFragility),value = T)
# no spaces and to lowercase
gsub(":\\s|\\s","_",columnNamesToClean)%>%tolower()
gsub(":\\s|\\s","_",grep(':',names(allFragility),value = T))%>%tolower()%>%sort()
# sorted new names
newNames=gsub(":\\s|\\s","_",columnNamesToClean)%>%
tolower()%>%
sort()
# then
names(allFragility)=c(names(allFragility)[1:4],newNames)
str(allFragility)
allFragility=do.call(rbind, dfs)
str(allFragility)
# woking on the names that have a ':'
grep(':',names(allFragility),value = T)
columnNamesToClean=grep(':',names(allFragility),value = T)
# Cleaning: no spaces and to lowercase
gsub(":\\s|\\s","_",columnNamesToClean)%>%tolower()
# sorted new names
newNames=gsub(":\\s|\\s","_",columnNamesToClean)%>%
tolower()
# then
names(allFragility)=c(names(allFragility)[1:4],newNames)
str(allFragility)
table(allFragility$Year)
allFragility[,-c(1:4)]
names(allFragility)[,-c(1:4)]
names(allFragility)[-c(1:4)]
sort(names(allFragility)[-c(1:4)])
allFragility[,sort(names(allFragility)[-c(1:4)])]
allFragility[,-c(1:4)]#=allFragility[,sort(names(allFragility)[-c(1:4)])]
allFragility[,-c(1:4)]=allFragility[,sort(names(allFragility)[-c(1:4)])]
head(allFragility)
allFragility=do.call(rbind, dfs)
str(allFragility)
View(allFragility)
# woking on the names that have a ':'
grep(':',names(allFragility),value = T)
columnNamesToClean=grep(':',names(allFragility),value = T)
# Cleaning: no spaces and to lowercase
gsub(":\\s|\\s","_",columnNamesToClean)%>%tolower()
# sorted new names
newNames=gsub(":\\s|\\s","_",columnNamesToClean)%>%
tolower()
# then
names(allFragility)=c(names(allFragility)[1:4],newNames)
str(allFragility)
#allFragility[,-c(1:4)]=
allFragility[,sort(names(allFragility)[-c(1:4)])]
#allFragility[,-c(1:4)]=
cbind(allFragility[,c(1:4)],allFragility[,sort(names(allFragility)[-c(1:4)])]
#allFragility[,-c(1:4)]=
cbind(allFragility[,c(1:4)],allFragility[,sort(names(allFragility)[-c(1:4)])])
allFragility[,-c(1:4)]=allFragility[,sort(names(allFragility)[-c(1:4)])]
head(allFragility)
allFragility=do.call(rbind, dfs)
str(allFragility)
# woking on the names that have a ':'
grep(':',names(allFragility),value = T)
columnNamesToClean=grep(':',names(allFragility),value = T)
# Cleaning: no spaces and to lowercase
gsub(":\\s|\\s","_",columnNamesToClean)%>%tolower()
# sorted new names
newNames=gsub(":\\s|\\s","_",columnNamesToClean)%>%
tolower()
# then
names(allFragility)=c(names(allFragility)[1:4],newNames)
str(allFragility)
allFragility[,-c(1:4)]=allFragility[,sort(names(allFragility)[-c(1:4)])]
allFragility=do.call(rbind, dfs)
columnNamesToClean=grep(':',names(allFragility),value = T)
# Cleaning: no spaces and to lowercase
gsub(":\\s|\\s","_",columnNamesToClean)%>%tolower()
# sorted new names
newNames=gsub(":\\s|\\s","_",columnNamesToClean)%>%
tolower()
# then
names(allFragility)=c(names(allFragility)[1:4],newNames)
str(allFragility)
allFragility=cbind(allFragility[,c(1:4)],allFragility[,sort(names(allFragility)[-c(1:4)])])
head(allFragility)
table(allFragility$Year)
as.Date(38718, origin="1899-12-30")
str(allFragility$Year)
allFragility$Year=as.numeric(allFragility$Year)
# temproral Column:
allFragility$Year2=format(as.Date(allFragility$Year,
origin="1899-12-30"),
"%Y") # I will just recover the year.
# improved column
allFragility$Year=ifelse(allFragility$Year%in%c(2021,2023),
allFragility$Year,
allFragility$Year2)
# deleting temporal
allFragility$Year2=NULL
# as numeric
allFragility$Year=as.numeric(allFragility$Year)
# now
table(allFragility$Year)
str(allFragility)
allFragility[,-c(1:3)]=lapply(allFragility[,-c(1:3)],as.numeric)
str(allFragility)
saveRDS(allFragility,'allFragility.rds')
saveRDS(allFragility,'allFragility_ok.rds')
linkFragile='https://github.com/Estadistica-AnalisisPolitico/operations_onDFs/raw/refs/heads/main/data/allFragility_ok.rds'
fragile=readRDS(url(linkFragile))
str(fragile)
table(fragile$Year)
head(fragile)
head(fragile[,c('Country','Year','Total')])
head(fragile[fragile$Year==2023,c('Country','c1_security_apparatus',	'c2_factionalized_elites',	'c3_group_grievance')])
fragileWide=tidyr::pivot_wider(fragile[,c('Country','Year','Total')],
names_from = Year,
values_from = Total,
names_sort=T)
fragileWide
boxplot(fragileWide[,-1])
library(ggplot2)
base=ggplot(fragileWide)
base+geom_boxplot(aes(x=as.ordered(2006),y=`2006`)) +
geom_boxplot(aes(x=as.ordered(2010),y=`2010`)) +
geom_boxplot(aes(x=as.ordered(2015),y=`2015`)) + labs(y='')
setwd("~/Documents/GITHUBs/PUCP/PreGrado/EAP2_gits/operations_onDFs")
rmarkdown::convert_ipynb('Fuzzy_R.ipynb', output = 'Fuzzy_R.Rmd')
demoIndex="https://docs.google.com/spreadsheets/d/e/2PACX-1vQWJnw11Xd2TvEd0p6_6d2NhtG29T9D_85ooNB4yddfIVH_LBaqiYroAD3sZzD1wvOxBPpj68gPcPsi/pub?gid=0&single=true&output=csv"
debtIndex="https://docs.google.com/spreadsheets/d/e/2PACX-1vQWJnw11Xd2TvEd0p6_6d2NhtG29T9D_85ooNB4yddfIVH_LBaqiYroAD3sZzD1wvOxBPpj68gPcPsi/pub?gid=1301926611&single=true&output=csv"
demo=read.csv(demoIndex)
debt=read.csv(debtIndex)
str(demo)
str(debt)
merge(demo,debt, by.x='name', by.y='name')
onlyInDemo=sort(setdiff(demo$name,debt$name))
onlyInDemo
onlyInDebt=sort(setdiff(debt$name,demo$name))
onlyInDebt
stringdist::stringdist(onlyInDemo[1],onlyInDebt,method = 'jaccard')
TheMatch<-character()
mindist<-integer()
sortedmatches<-character()
for (i in 1:length(onlyInDemo) ) {
allDistances<-stringdist::stringdist(onlyInDemo[i],onlyInDebt,method = 'jw')
mindist[i]=min(allDistances)
TheMatch[i]<-onlyInDebt[which.min(allDistances)]
}
fuzzyOutput=data.frame(input=onlyInDemo,possible_match=TheMatch,divergence=mindist,  stringsAsFactors = F)
fuzzyOutput[order(-fuzzyOutput$divergence),]
TheMatch<-character()
mindist<-integer()
sortedmatches<-character()
for (i in 1:length(onlyInDemo) ) {
allDistances<-stringdist::stringdist(onlyInDemo[i],onlyInDebt,method = 'jw')
mindist[i]=min(allDistances)
TheMatch[i]<-onlyInDebt[which.min(allDistances)]
}
fuzzyOutput=data.frame(input=onlyInDemo,possible_match=TheMatch,divergence=mindist,  stringsAsFactors = F)
fuzzyOutput[order(-fuzzyOutput$divergence),]
best_fuzzy_1=fuzzyOutput[fuzzyOutput$divergence<=0.23,]
best_fuzzy_1
demo$name[match(best_fuzzy_1$input, demo$name)] = best_fuzzy_1$possible_match
onlyInDemo=sort(setdiff(demo$name,debt$name))
onlyInDebt=sort(setdiff(debt$name,demo$name))
TheMatch<-character()
mindist<-integer()
sortedmatches<-character()
for (i in 1:length(onlyInDemo) ) {
allDistances<-stringdist::stringdist(onlyInDemo[i],onlyInDebt,method = 'jw')
mindist[i]=min(allDistances)
TheMatch[i]<-onlyInDebt[which.min(allDistances)]
}
fuzzyOutput=data.frame(input=onlyInDemo,possible_match=TheMatch,divergence=mindist,  stringsAsFactors = F)
fuzzyOutput[order(-fuzzyOutput$divergence),]
best_fuzzy_2=fuzzyOutput[c(4,3,9,1,2),]
best_fuzzy_2
demo$name[match(best_fuzzy_2$input, demo$name)] = best_fuzzy_2$possible_match
onlyInDemo=sort(setdiff(demo$name,debt$name))
onlyInDebt=sort(setdiff(debt$name,demo$name))
TheMatch<-character()
mindist<-integer()
sortedmatches<-character()
for (i in 1:length(onlyInDemo) ) {
allDistances<-stringdist::stringdist(onlyInDemo[i],onlyInDebt,method = 'jw')
mindist[i]=min(allDistances)
TheMatch[i]<-onlyInDebt[which.min(allDistances)]
}
fuzzyOutput=data.frame(input=onlyInDemo,possible_match=TheMatch,divergence=mindist,  stringsAsFactors = F)
fuzzyOutput[order(-fuzzyOutput$divergence),]
TheMatch<-character()
mindist<-integer()
sortedmatches<-character()
for (i in 1:length(onlyInDemo) ) {
allDistances<-stringdist::stringdist(onlyInDemo[i],onlyInDebt,method = 'cosine')
mindist[i]=min(allDistances)
TheMatch[i]<-onlyInDebt[which.min(allDistances)]
}
fuzzyOutput=data.frame(input=onlyInDemo,possible_match=TheMatch,divergence=mindist,  stringsAsFactors = F)
fuzzyOutput[order(-fuzzyOutput$divergence),]
best_fuzzy_3=fuzzyOutput[c(1,5),]
best_fuzzy_3
best_fuzzy_3=rbind(best_fuzzy_3,c('Swaziland','Eswatini',NA))
best_fuzzy_3
demo$name[match(best_fuzzy_3$input, demo$name)] = best_fuzzy_3$possible_match
str(merge(demo,debt, by.x='name', by.y='name'))
demodebt=merge(demo,debt, by.x='name', by.y='name')
str(demodebt)
casesSumByStateAndMonth%>%head()
casesSumByStateAndMonth%>%head(20)
# by.x='name', by.y='name' are NOT NEEDED
merge(demo,debt, by.x='name', by.y='name')%>%head(30)
install.packages("DHARMa")
